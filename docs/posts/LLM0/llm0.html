<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.121">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Maria Prokofieva">
<meta name="dcterms.date" content="2023-11-02">

<title>MyDataRules (MyDR) - Intro into LLM</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon-16x16.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-MB64NTVJTB"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-MB64NTVJTB', { 'anonymize_ip': true});
</script>


<meta property="og:title" content="MyDataRules (MyDR) - Intro into LLM">
<meta property="og:description" content="">
<meta property="og:site-name" content="MyDataRules">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">MyDataRules (MyDR)</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index_b.html" rel="" target="">
 <span class="menu-text">Whatâ€™s new</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html" rel="" target="">
 <span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.meetup.com/r-business/" rel="" target="">
 <span class="menu-text">Meetup</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/m45hap" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Intro into LLM</h1>
  <div class="quarto-categories">
    <div class="quarto-category">data</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Maria Prokofieva </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 2, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="purpose" class="level1">
<h1>Purpose</h1>
<p>Bootstrap knowledge of LLMs ASAP. With a bias/focus to GPT.</p>
<p>Avoid being a link dump. Try to provide only valuable well tuned information.</p>
<section id="prelude" class="level2">
<h2 class="anchored" data-anchor-id="prelude">Prelude</h2>
<p>Neural network links before starting with transformers.</p>
<ul>
<li>https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi</li>
<li>https://www.3blue1brown.com/topics/neural-networks</li>
<li>http://neuralnetworksanddeeplearning.com/</li>
<li>https://distill.pub/</li>
</ul>
</section>
<section id="key" class="level2">
<h2 class="anchored" data-anchor-id="key">Key</h2>
<ul>
<li>ğŸŸ¢ = easy, ğŸŸ  = medium, ğŸ”´ = hard</li>
<li>ğŸ•°ï¸ = long, ğŸ™‰ = low quality audio</li>
</ul>
</section>
<section id="youtube-lessons" class="level2">
<h2 class="anchored" data-anchor-id="youtube-lessons">Youtube Lessons</h2>
<ul>
<li>ğŸŸ¢ğŸ•°ï¸ <strong>Åukasz Kaiser</strong> <a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">Attention is all you need; Attentional Neural Network Models</a> This talk is from 6 years ago.</li>
<li>ğŸŸ¢ğŸ•°ï¸ <strong>Andrej Karpathy</strong> <a href="https://www.youtube.com/watch?v=PaCmpygFfXo">The spelled-out intro to language modeling: building makemore</a>: basic. bi-gram name generator model by counting, then by NN. using pytorch.</li>
<li>ğŸŸ¢ğŸ•°ï¸ <strong>Andrej Karpathy</strong> <a href="https://www.youtube.com/watch?v=TCH_1BHY58I">Building makemore Part 2: MLP</a>:</li>
<li>ğŸ•°ï¸ <strong>Andrej Karpathy</strong> <a href="https://www.youtube.com/watch?v=P6sfmUTpUmc">Building makemore Part 3: Activations &amp; Gradients, BatchNorm</a>):</li>
<li>ğŸ•°ï¸ <strong>Andrej Karpathy</strong> <a href="https://www.youtube.com/watch?v=q8SA3rM6ckI">Building makemore Part 4: Becoming a Backprop Ninja</a>:</li>
<li>ğŸŸ¢ <strong>Hedu AI</strong> <a href="https://www.youtube.com/watch?v=dichIcUZfOw">Visual Guide to Transformer Neural Networks - (Episode 1) Position Embeddings</a>: Tokens are embedded into a semantic space. sine/cosine position encoding explained very well.</li>
<li>ğŸŸ¢ <strong>Hedu AI</strong> <a href="https://www.youtube.com/watch?v=mMa2PmYJlCo">Visual Guide to Transformer Neural Networks - (Episode 2) Multi-Head &amp; Self-Attention</a>: Clear overview of multi-head attention.</li>
<li>ğŸŸ¢ <strong>Hedu AI</strong> <a href="https://www.youtube.com/watch?v=gJ9kaJsE78k">Visual Guide to Transformer Neural Networks - (Episode 3) Decoderâ€™s Masked Attention</a>: Further details on the transformer architecture.</li>
<li>ğŸŸ ğŸ•°ï¸ <strong>Andrej Karpathy</strong> <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Andrej Karpathy - Letâ€™s build GPT: from scratch, in code, spelled out.</a>: build up a Shakespeare gpt-2-like from scratch. starts with bi-gram and adds features one by one. pytorch.</li>
<li>ğŸ”´ğŸ•°ï¸ <strong>Chris Olah</strong> <a href="https://www.youtube.com/watch?v=pC4zRb_5noQ">CS25 I Stanford Seminar - Transformer Circuits, Induction Heads, In-Context Learning</a>: Interpretation. Deep look into the mechanics of induction heads. <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">Companion article</a></li>
<li>ğŸŸ¢ <strong>Jay Alammar</strong> <a href="https://www.youtube.com/watch?v=ISPId9Lhc1g">The Illustrated Word2vec - A Gentle Intro to Word Embeddings in Machine Learning</a></li>
<li>ğŸŸ¢ <strong>Jay Alammar</strong> <a href="https://www.youtube.com/watch?v=MQnJZuBGmSQ">How GPT3 Works - Easily Explained with Animations</a>: extremely high level basic overview.</li>
<li>ğŸŸ¢ğŸ•°ï¸ <strong>Jay Alammar</strong> <a href="https://www.youtube.com/watch?v=-QH8fRhqFHM">The Narrated Transformer Language Model</a>: much deeper look at the architecture. goes into detail. <a href="https://jalammar.github.io/illustrated-transformer/">Companion article</a>.</li>
<li><strong>Sebastian Raschka</strong> <a href="https://sebastianraschka.com/blog/2021/dl-course.html#l19-self-attention-and-transformer-networks">L19: Self-attention and transformer networks</a> Academic style lecture series on self-attention transformers</li>
<li>ğŸŸ¢ğŸ•°ï¸ğŸ™‰ <strong>Mark Chen</strong> <a href="https://www.youtube.com/watch?v=qGkzHFllWDY">Transformers in Language: The development of GPT Models including GPT3</a> A chunk of this lecture is about applying GPT to images. Same lecture series as the Chris Olah one. <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM">Rest of the series</a>. Papers listed in the talk:
<ul>
<li>â€œGPT-1â€: <strong>Liu et. al.</strong> <a href="https://arxiv.org/abs/1801.10198">Generating Wikipedia by Summarizing Long Sequences</a></li>
<li>â€œGPT-2â€: <strong>Radford et. al.</strong> <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a> <a href="https://github.com/openai/gpt-2">github.com/openai/gpt-2</a> <a href="https://openai.com/research/better-language-models">OpenAI: Better Language Models</a> <a href="https://www.fermatslibrary.com/s/language-models-are-unsupervised-multitask-learners">Fermats Library</a></li>
<li>â€œGPT-3â€: <strong>Brown et. al.</strong> <a href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a> (I think this is it, canâ€™t find the quoted text inside this paper)</li>
</ul></li>
</ul>
</section>
</section>
<section id="articles" class="level1">
<h1>Articles</h1>
<ul>
<li>ğŸŸ  <strong>Jay Mody</strong> <a href="https://jaykmody.com/blog/gpt-from-scratch/">GPT in 60 Lines of NumPy</a></li>
<li>ğŸŸ  <strong>PyTorch</strong> <a href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">Language Modeling with nn.Transformer and TorchText</a></li>
<li>ğŸŸ  <strong>Sasha Rush et. al.</strong> <a href="http://nlp.seas.harvard.edu/annotated-transformer/">The Annotated Transformer</a></li>
<li>ğŸŸ¢ <strong>Jay Alammar</strong> <a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> companion video above.</li>
<li>ğŸ”¥ <strong>Chris Olah et. al.</strong> <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">In-context Learning and Induction Heads</a> companion video lecture above</li>
</ul>
</section>
<section id="research-paper-lists" class="level1">
<h1>Research Paper Lists</h1>
<ul>
<li><strong>Sebastian Raschka</strong> <a href="https://sebastianraschka.com/blog/2023/llm-reading-list.html">Understanding Large Language Models â€“ A Transformative Reading List</a> This article lists some of the most important papers in the area.</li>
<li><strong>OpenAI</strong> <a href="https://openai.com/research">Research Index</a></li>
</ul>
</section>
<section id="research-papers" class="level1">
<h1>Research Papers</h1>
<ul>
<li><strong>Radford et. al.</strong> <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training (2018)</a> a page accompanying this paper on the OpenAI blog <a href="https://openai.com/research/language-unsupervised">Improving language understanding with unsupervised learning</a></li>
<li><strong>Kaplan et. al.</strong> <a href="https://arxiv.org/abs/2001.08361">Scaling Laws for Neural Language Models</a> A variety of models were trained using varying amounts of compute, data set size, and number of parameters. This enables us to predict what parameters will work well in larger future models. See also <strong>Gwern Branwen</strong> <a href="https://gwern.net/scaling-hypothesis">The Scaling Hypothesis</a></li>
</ul>
</section>
<section id="philosophy-of-gpt" class="level1">
<h1>Philosophy of GPT</h1>
<ul>
<li><strong>Isaac Asimov</strong> <a href="http://users.ece.cmu.edu/~gamvrosi/thelastq.html">The Last Question (1956)</a></li>
<li><strong>Justin Weinberg, Daily Nous</strong> <a href="https://dailynous.com/2020/07/30/philosophers-gpt-3/">Philosophers On GPT-3</a></li>
<li><strong>Fernando Borretti</strong> <a href="https://borretti.me/article/and-yet-it-understands">And Yet It Understands</a></li>
<li><strong>Ted Chiang</strong> <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web">ChatGPT Is a Blurry JPEG of the Web</a></li>
<li><strong>Noam Chomsky</strong> <a href="https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html">The False Promise of ChatGPT</a></li>
</ul>
<p><em>This page is not finished yet. I will continue adding to this.</em></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2023, Maria Prokofieva</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://www.meetup.com/r-business/">Meetup</a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/m45hap">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>